Dear AdaCore,
 Another optimization-related query arising from SPARKNaCl...

Perhaps this should be assigned to Eric B, or anyone else from the back-end team?

---

I realized there was another optimization opportunity in SPARKNaCl, where the code (in Ada terms at least)
has a 64-bit integer multiply that could actually be safely done in 32-bits. This is good news, since 64-bit
multiplies are expensive on 32-but machines like RV32.

The inner loop in question is in the body of SPARKNaCl."*"

This is doing a ladder-multiplication of a big integer, multiplying and accumulating coefficients of the answer.

It's basically doing

  T (I) := T (I) + (LT * I64 (Right (0)));

where LT and the elements of T are all 64-bit signed integers, so that "*" is the "*" for
Interfaces.Integer_64.  Looking in the generated code at -O0 on RV32, the "*" actually generates
4 instructions - three "mul" and one "mulhu"

I realized that "*" could actually be done in 32-bit arithmetic because we actually know that LT
and Right (0) are limited to be in 0 .. 65535, so the result of a multiplication will fit in
Unsigned_32.

So I simply changed the type of LT to Unsigned_32, and each line of the inner loop to something like this:

  T (I) := T (I) + I64 (LT * Unsigned_32 (Right (0)));

so the "*" in there should be 1 instruction on RV32.

This gives a huge performance boost at -O0, but (to my great surprise) no change at all at -O1 and above.

I looked again at the generated code for the first version at -O1 and it is achieving
the same optimization automatically - basically generating a single "mul" instruction
for that line of code.

This is very impressive. Somehow, -O1 has realized that both the operands of a 64-bit "*" are
in 0 .. 65535, and therefore has "narrowed" the multiplication to 32 bits.

I cannot see this in the GIMPLE anywhere. For example, looking in the
sparknacl.adb.232t.optimized file, I see something like this:

  interfaces__Tinteger_64B _6;

  _4 = right_115(D)->F[0];
  _5 = (interfaces__Tinteger_64B) _4;

  _165 = (void *) ivtmp.289_159;
  _2 = MEM[base: _165, offset: 0B];
  lt_114 = (sparknacl__gf64_normal_limb___XDLU_0__65535) _2;

  _166 = (void *) ivtmp.290_162;
  _3 = MEM[base: _166, offset: 0B];
  _6 = _5 * lt_114;
  _7 = _3 + _6;

so it seems to be dealing with 64-bit integer types at this point.

Does this optimization appear later in the RTL? (Sorry... I tried, but really can't read the RTL...)
Which optimization phase is responsible?

Notably: this trick appears to be impossible in the C version, since the code has no indication of
the constrained ranges of the variables involved... another good day for numeric subtypes!

Oh.. to see the real code, look at the head of the "faster_mul" branch on the SPARKNaCl GitHub repo, and
compare that with the head of "master" to see what I changed...

Thanks,
 Rod
