## To Slice or not to Slice? (Git Tag: No_Slices)
The NaCl "Sign" operations uses the SHA512 hash algorithm three times to form a single signature, so I thought it would be another good place to look for performance improvement.

The inner loop of SHA512 repeatedly stores a group of 8 bytes into a Unsigned_64 value, but does so in *big-endian* format, so the first byte becomes the most-significant 8 bits of the result.  To do that, SPARKNaCl declares a simple converison function, called DL64. The original version, translated from the TweetNaCl original, looks like this:


function DL64 (X : in Bytes_8) return U64
is
   U : U64 := 0;
begin
   for I in X'Range loop
      U := Shift_Left (U, 8) or U64 (X (I));
   end loop;
   return U;
end DL64;



which looks simple enough. Note that Bytes_8 is a *constrained* array of Byte (with index value 0 .. 7) and that the Shift_Left and "or" operators here are both operating on 64-bit unsigned values.

In the main loop of SHA512, DL64 gets called many times, converting each group of 8 bytes from a 128 byte block. The "natural" way to write this in SPARK is to use array "slices" to pick out the right group of bytes, and then convert each slice to Bytes_8 to fix the bounds to those expected by DL64. This is all done in one big aggregate assignment that looks like this:


W := (0  => DL64 (Bytes_8 (M (CB + 0 .. CB + 7))),
      1  => DL64 (Bytes_8 (M (CB + 8 .. CB + 15))),
      2  => DL64 (Bytes_8 (M (CB + 16 .. CB + 23))),
      3  => DL64 (Bytes_8 (M (CB + 24 .. CB + 31))),
      -- and so on...
      15 => DL64 (Bytes_8 (M (CB + 120 .. CB + 127))));


This looks elegant, but all those slices are probably a bit slow compared to the C where it's all done with a trivial bit of pointer arithmetic.

I decided to re-write this to see if I could avoid the slices altogether.  The first step is to re-declare DL64 so it takes *two* parameters - a general unconstrained array of bytes X, and an offset value I here it should start picking bytes out of that array. It also needs a suitable precondition that states that there must be at least 8 bytes in X starting at position I, so the new specification looks like this:


function DL64 (X : in Byte_Seq;
               I : in N32) return U64
  with Global => null,
       Pre => X'Length >= 8 and then
              I >= X'First and then
              I <= X'Last - 7;


I also realized that I could re-write the body to avoid looping, and to use 32-bit Shifts and logical operators most of the time, since that will be more efficient on our RV32 CPU. It now looks like this:


function DL64 (X : in Byte_Seq;
               I : in N32) return U64
is
   LSW, MSW : U32;
begin
   --  Doing this in two 32-bit groups avoids the need
   --  for 64-bit shifts on 32-bit machines.
   MSW := Shift_Left (U32 (X (I)),     24) or
     Shift_Left (U32 (X (I + 1)), 16) or
     Shift_Left (U32 (X (I + 2)), 8) or
     U32 (X (I + 3));
   LSW := Shift_Left (U32 (X (I + 4)), 24) or
     Shift_Left (U32 (X (I + 5)), 16) or
     Shift_Left (U32 (X (I + 6)), 8) or
     U32 (X (I + 7));

   --  Just one 64-bit shift and an "or" is now required
   return Shift_Left (U64 (MSW), 32) or U64 (LSW);
end DL64;


With that in place, the calling code is much simpler and avoids the need for array slices and conversions:


W := (0  => DL64 (M, CB),
      1  => DL64 (M, CB + 8),
      2  => DL64 (M, CB + 16),
      --  and so on...
      15 => DL64 (M, CB + 120));


With that in place, the performance figures look like this:

|Level|Timing_Baseline|Relax_Init|PRE_Scalarmult|Unroll_Multiply|No_Slices|
|:-------:|-------:|---:|---:|---:|---:|
|-O0|198.03|191.54|191.40|176.50|177.40|
|-O1|98.03|95.26|95.03|69.88|69.79|
|-O2|93.86|88.66|87.06|63.61|58.31|

so a bit worse at -O0, a bit better at -O1, and noticeably better at -O2.
